"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API –∑–∞–ø—Ä–æ—Å–æ–≤:
- –ê–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
- –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü —Å –æ—Ç–∑—ã–≤–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–π
"""
import asyncio
import httpx
import time
from typing import List, Dict, Optional
from urllib.parse import quote


# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BASE_URL = "https://safelogist.net"  # –ë–∞–∑–æ–≤—ã–π URL API
LANG = "ru"  # –Ø–∑—ã–∫: ru, en, uk, ro
REQUESTS_PER_SECOND = 10  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É


async def autocomplete_search(
    client: httpx.AsyncClient,
    query: str,
    limit: int = 10
) -> Dict:
    """
    –ó–∞–ø—Ä–æ—Å –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
    """
    url = f"{BASE_URL}/api/reviews/search"
    params = {
        "q": query,
        "limit": limit
    }
    
    try:
        response = await client.get(url, params=params)
        if response.status_code == 200:
            data = response.json()
            return {
                "success": True,
                "query": query,
                "companies": data.get("companies", []),
                "count": len(data.get("companies", []))
            }
        else:
            return {
                "success": False,
                "query": query,
                "status": response.status_code,
                "error": response.text
            }
    except Exception as e:
        return {
            "success": False,
            "query": query,
            "error": str(e)
        }


async def get_reviews_list_page(
    client: httpx.AsyncClient,
    page: int = 1,
    lang: str = LANG
) -> Dict:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–æ —Å–ø–∏—Å–∫–æ–º –∫–æ–º–ø–∞–Ω–∏–π
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        lang: –Ø–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∑–∞–ø—Ä–æ—Å–∞
    """
    url = f"{BASE_URL}/{lang}/reviews"
    params = {"page": page}
    
    try:
        response = await client.get(url, params=params)
        if response.status_code == 200:
            html = response.text
            return {
                "success": True,
                "page": page,
                "type": "list",
                "status": response.status_code,
                "html_length": len(html),
                "url": str(response.url)
            }
        else:
            return {
                "success": False,
                "page": page,
                "type": "list",
                "status": response.status_code,
                "error": response.text
            }
    except Exception as e:
        return {
            "success": False,
            "page": page,
            "type": "list",
            "error": str(e)
        }


async def get_company_reviews_page(
    client: httpx.AsyncClient,
    company_id: int,
    page: int = 1,
    lang: str = LANG
) -> Dict:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –æ—Ç–∑—ã–≤–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏–∏
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        company_id: ID –∫–æ–º–ø–∞–Ω–∏–∏
        page: –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        lang: –Ø–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∑–∞–ø—Ä–æ—Å–∞
    """
    url = f"{BASE_URL}/{lang}/reviews/item/{company_id}"
    params = {"page": page}
    
    try:
        response = await client.get(url, params=params)
        if response.status_code == 200:
            html = response.text
            return {
                "success": True,
                "company_id": company_id,
                "page": page,
                "status": response.status_code,
                "html_length": len(html),
                "url": str(response.url)
            }
        else:
            return {
                "success": False,
                "company_id": company_id,
                "page": page,
                "status": response.status_code,
                "error": response.text
            }
    except Exception as e:
        return {
            "success": False,
            "company_id": company_id,
            "page": page,
            "error": str(e)
        }


class RateLimiter:
    """–û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    def __init__(self, rate: float):
        self.rate = rate  # –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
        self.allowance = rate
        self.last_check = time.time()
        self.lock = asyncio.Lock()
    
    async def acquire(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞"""
        async with self.lock:
            current = time.time()
            time_passed = current - self.last_check
            self.last_check = current
            self.allowance += time_passed * self.rate
            
            if self.allowance > self.rate:
                self.allowance = self.rate
            
            if self.allowance < 1.0:
                sleep_time = (1.0 - self.allowance) / self.rate
                await asyncio.sleep(sleep_time)
                self.allowance = 0.0
            else:
                self.allowance -= 1.0


async def load_page_with_stats(
    client: httpx.AsyncClient,
    company_id: int,
    page: int,
    semaphore: asyncio.Semaphore,
    request_num: int,
    total_requests: int
) -> Dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–º–ø–∞–Ω–∏–∏ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞"""
    async with semaphore:
        start_time = time.time()
        result = await get_company_reviews_page(client, company_id, page)
        elapsed = time.time() - start_time
        
        result["request_num"] = request_num
        result["total_requests"] = total_requests
        result["elapsed"] = elapsed
        
        return result


async def load_list_page_with_stats(
    client: httpx.AsyncClient,
    page: int,
    semaphore: asyncio.Semaphore,
    request_num: int,
    total_requests: int
) -> Dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞"""
    async with semaphore:
        start_time = time.time()
        result = await get_reviews_list_page(client, page)
        elapsed = time.time() - start_time
        
        result["request_num"] = request_num
        result["total_requests"] = total_requests
        result["elapsed"] = elapsed
        
        return result


async def test_autocomplete_queries(
    client: httpx.AsyncClient,
    queries: List[str],
    rate_limiter: Optional[RateLimiter] = None
):
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        queries: –°–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        rate_limiter: –û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    print("\n" + "="*60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–í–¢–û–ö–û–ú–ü–õ–ò–¢–ê")
    print("="*60)
    
    results = []
    total_start = time.time()
    
    for i, query in enumerate(queries, 1):
        if rate_limiter:
            await rate_limiter.acquire()
        
        print(f"\nüîç –ü–æ–∏—Å–∫ {i}/{len(queries)}: '{query}'")
        start_time = time.time()
        result = await autocomplete_search(client, query)
        elapsed = time.time() - start_time
        
        if result["success"]:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {result['count']}")
            if result["companies"]:
                print("   –ü—Ä–∏–º–µ—Ä—ã:")
                for j, company in enumerate(result["companies"][:3], 1):
                    print(f"   {j}. {company.get('name', 'N/A')} (ID: {company.get('id', 'N/A')})")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', result.get('status', 'Unknown'))}")
        
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed:.2f}—Å")
        results.append(result)
    
    total_elapsed = time.time() - total_start
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    successful = sum(1 for r in results if r["success"])
    total_companies = sum(r.get("count", 0) for r in results if r["success"])
    avg_time = total_elapsed / len(queries) if queries else 0
    actual_rate = len(queries) / total_elapsed if total_elapsed > 0 else 0
    
    print("\n" + "-"*60)
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {successful}/{len(queries)}")
    print(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–º–ø–∞–Ω–∏–π: {total_companies}")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_elapsed:.2f}—Å")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—Ä–æ—Å: {avg_time:.2f}—Å")
    print(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: {actual_rate:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
    print("-"*60)
    
    return results


async def test_company_pages(
    client: httpx.AsyncClient,
    company_ids: List[int],
    pages: List[int] = None,
    rate_limiter: Optional[RateLimiter] = None
):
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –∫–æ–º–ø–∞–Ω–∏–π
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        company_ids: –°–ø–∏—Å–æ–∫ ID –∫–æ–º–ø–∞–Ω–∏–π
        pages: –°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é [1])
        rate_limiter: –û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    if pages is None:
        pages = [1]
    
    print("\n" + "="*60)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–¢–†–ê–ù–ò–¶ –ö–û–ú–ü–ê–ù–ò–ô")
    print("="*60)
    
    results = []
    total_start = time.time()
    total_requests = len(company_ids) * len(pages)
    request_num = 0
    
    for company_id in company_ids:
        for page in pages:
            request_num += 1
            if rate_limiter:
                await rate_limiter.acquire()
            
            print(f"\nüìÑ –ó–∞–ø—Ä–æ—Å {request_num}/{total_requests}: –ö–æ–º–ø–∞–Ω–∏—è ID: {company_id}, –°—Ç—Ä–∞–Ω–∏—Ü–∞: {page}")
            start_time = time.time()
            result = await get_company_reviews_page(client, company_id, page)
            elapsed = time.time() - start_time
            
            if result["success"]:
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
                print(f"   –†–∞–∑–º–µ—Ä HTML: {result['html_length']:,} –±–∞–π—Ç")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', result.get('status', 'Unknown'))}")
            
            print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed:.2f}—Å")
            results.append(result)
    
    total_elapsed = time.time() - total_start
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    successful = sum(1 for r in results if r["success"])
    avg_time = total_elapsed / len(results) if results else 0
    actual_rate = len(results) / total_elapsed if total_elapsed > 0 else 0
    
    print("\n" + "-"*60)
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {successful}/{len(results)}")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_elapsed:.2f}—Å")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—Ä–æ—Å: {avg_time:.2f}—Å")
    print(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: {actual_rate:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
    print("-"*60)
    
    return results


async def test_combined_flow(
    client: httpx.AsyncClient,
    search_query: str,
    rate_limiter: Optional[RateLimiter] = None
):
    """
    –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç: –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç, –∑–∞—Ç–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        search_query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        rate_limiter: –û–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    """
    print("\n" + "="*60)
    print(f"–ö–û–ú–ë–ò–ù–ò–†–û–í–ê–ù–ù–´–ô –¢–ï–°–¢: '{search_query}'")
    print("="*60)
    
    # 1. –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç
    if rate_limiter:
        await rate_limiter.acquire()
    print(f"\n1Ô∏è‚É£ –ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π: '{search_query}'")
    autocomplete_result = await autocomplete_search(client, search_query, limit=5)
    
    if not autocomplete_result["success"] or not autocomplete_result["companies"]:
        print("‚ùå –ö–æ–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
    
    companies = autocomplete_result["companies"]
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(companies)} –∫–æ–º–ø–∞–Ω–∏–π")
    
    # 2. –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
    print(f"\n2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∫–æ–º–ø–∞–Ω–∏–π...")
    for i, company in enumerate(companies, 1):
        company_id = company.get("id")
        company_name = company.get("name", "N/A")
        
        if not company_id:
            print(f"   {i}. {company_name} - –ø—Ä–æ–ø—É—â–µ–Ω–æ (–Ω–µ—Ç ID)")
            continue
        
        if rate_limiter:
            await rate_limiter.acquire()
        
        print(f"   {i}. {company_name} (ID: {company_id})")
        result = await get_company_reviews_page(client, company_id, page=1)
        
        if result["success"]:
            print(f"      ‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({result['html_length']:,} –±–∞–π—Ç)")
        else:
            print(f"      ‚ùå –û—à–∏–±–∫–∞: {result.get('error', result.get('status', 'Unknown'))}")


async def get_companies_dynamically(
    client: httpx.AsyncClient,
    search_queries: Optional[List[str]] = None,
    companies_per_query: int = 5,
    max_total_companies: int = 20,
    num_queries: int = 10
) -> List[Dict]:
    """
    –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∫–æ–º–ø–∞–Ω–∏–π —á–µ—Ä–µ–∑ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        search_queries: –°–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–µ—Å–ª–∏ None - –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        companies_per_query: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π –Ω–∞ –∑–∞–ø—Ä–æ—Å
        max_total_companies: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π
        num_queries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ search_queries –Ω–µ —É–∫–∞–∑–∞–Ω)
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –∫–æ–º–ø–∞–Ω–∏—è—Ö {id, name}
    """
    import random
    import string
    
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–µ
    if search_queries is None:
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        base_queries = [
            "–¢–û–í", "–û–û–û", "–ò–ü", "–§–û–ü", "–õ–æ–≥–∏—Å—Ç–∏–∫", "–¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç", 
            "–ü–µ—Ä–µ–≤–æ–∑–∫–∞", "–≠–∫—Å–ø–µ–¥–∏—Ü–∏—è", "–ì—Ä—É–∑", "–î–æ—Å—Ç–∞–≤–∫–∞",
            "–°–µ—Ä–≤–∏—Å", "–ö–æ–º–ø–∞–Ω–∏—è", "–¢—Ä–∞–Ω—Å", "–õ–æ–≥–∏—Å—Ç"
        ]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        # –ë—É–∫–≤—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        letters_ru = "–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è"
        letters_en = "abcdefghijklmnopqrstuvwxyz"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ 2-3 –±—É–∫–≤–µ–Ω–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
        random_queries = []
        for _ in range(num_queries - len(base_queries)):
            # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º —Ä—É—Å—Å–∫–∏–µ –∏–ª–∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –±—É–∫–≤—ã
            if random.random() > 0.5:
                letters = letters_ru
            else:
                letters = letters_en
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º 2-3 –±—É–∫–≤—ã
            length = random.randint(2, 3)
            query = ''.join(random.choice(letters) for _ in range(length))
            random_queries.append(query.upper() if random.random() > 0.5 else query)
        
        search_queries = base_queries + random_queries[:num_queries - len(base_queries)]
        # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        random.shuffle(search_queries)
        search_queries = search_queries[:num_queries]
    
    all_companies = []
    semaphore = asyncio.Semaphore(REQUESTS_PER_SECOND)
    
    async def fetch_companies(query: str):
        async with semaphore:
            result = await autocomplete_search(client, query, limit=companies_per_query)
            if result["success"] and result["companies"]:
                return result["companies"]
            return []
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    print(f"üîç –ü–æ–∏—Å–∫ –∫–æ–º–ø–∞–Ω–∏–π –ø–æ {len(search_queries)} –∑–∞–ø—Ä–æ—Å–∞–º...")
    print(f"   –ó–∞–ø—Ä–æ—Å—ã: {', '.join(search_queries[:10])}{'...' if len(search_queries) > 10 else ''}")
    coroutines = [fetch_companies(query) for query in search_queries]
    results = await asyncio.gather(*coroutines)
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏
    for companies in results:
        all_companies.extend(companies)
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ ID
    unique_companies = {}
    for company in all_companies:
        company_id = company.get("id")
        if company_id and company_id not in unique_companies:
            unique_companies[company_id] = company
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    companies_list = list(unique_companies.values())[:max_total_companies]
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(companies_list)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
    return companies_list


async def get_company_pages_count(
    client: httpx.AsyncClient,
    company_id: int,
    lang: str = LANG
) -> int:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ (–∑–∞–≥—Ä—É–∂–∞—è –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É)
    
    Args:
        client: httpx –∫–ª–∏–µ–Ω—Ç
        company_id: ID –∫–æ–º–ø–∞–Ω–∏–∏
        lang: –Ø–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü (–∏–ª–∏ 1 –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)
    """
    try:
        url = f"{BASE_URL}/{lang}/reviews/item/{company_id}"
        params = {"page": 1}
        response = await client.get(url, params=params, follow_redirects=True)
        
        if response.status_code == 200:
            html = response.text
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "–°—Ç—Ä–∞–Ω–∏—Ü–∞ 1 / X" –∏–ª–∏ "page 1 / X"
            import re
            patterns = [
                r'–°—Ç—Ä–∞–Ω–∏—Ü–∞\s+\d+\s+/\s+(\d+)',
                r'page\s+\d+\s+/\s+(\d+)',
                r'—Å—Ç—Ä–∞–Ω–∏—Ü–∞\s+\d+\s+–∏–∑\s+(\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, html, re.IGNORECASE)
                if match:
                    return int(match.group(1))
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 1 (–º–∏–Ω–∏–º—É–º –æ–¥–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞)
        return 1
    except Exception:
        return 1


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è API")
    print(f"üìç –ë–∞–∑–æ–≤—ã–π URL: {BASE_URL}")
    print(f"üåê –Ø–∑—ã–∫: {LANG}")
    print(f"‚ö° –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {REQUESTS_PER_SECOND} (–∫–∞–∫ {REQUESTS_PER_SECOND} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)")
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
    limits = httpx.Limits(max_keepalive_connections=20, max_connections=20)
    timeout = httpx.Timeout(30.0)
    
    async with httpx.AsyncClient(timeout=timeout, limits=limits) as client:
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–æ–ª—É—á–∞–µ–º –∫–æ–º–ø–∞–Ω–∏–∏ (–∑–∞–ø—Ä–æ—Å—ã –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        companies = await get_companies_dynamically(
            client,
            search_queries=None,  # None = –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            companies_per_query=5,
            max_total_companies=20,
            num_queries=15  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        )
        
        if not companies:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        
        print(f"\nüìã –ö–æ–º–ø–∞–Ω–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
        for i, company in enumerate(companies[:10], 1):
            print(f"   {i}. {company.get('name', 'N/A')} (ID: {company.get('id', 'N/A')})")
        if len(companies) > 10:
            print(f"   ... –∏ –µ—â–µ {len(companies) - 10} –∫–æ–º–ø–∞–Ω–∏–π")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
        print(f"\nüìÑ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏...")
        semaphore = asyncio.Semaphore(REQUESTS_PER_SECOND)
        
        async def get_pages_for_company(company: Dict):
            async with semaphore:
                company_id = company.get("id")
                if not company_id:
                    return None
                pages_count = await get_company_pages_count(client, company_id)
                return {
                    "company_id": company_id,
                    "company_name": company.get("name", "N/A"),
                    "pages_count": min(pages_count, 10)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 10 —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                }
        
        companies_with_pages = await asyncio.gather(*[
            get_pages_for_company(company) for company in companies
        ])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º None (–∫–æ–º–ø–∞–Ω–∏–∏ –±–µ–∑ ID)
        companies_with_pages = [c for c in companies_with_pages if c is not None]
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–¥–∞—á (–∫–æ–º–ø–∞–Ω–∏—è + —Å—Ç—Ä–∞–Ω–∏—Ü–∞)
        tasks = []
        for company_info in companies_with_pages:
            company_id = company_info["company_id"]
            pages_count = company_info["pages_count"]
            for page in range(1, pages_count + 1):
                tasks.append((company_id, page, company_info["company_name"]))
        
        total_requests = len(tasks)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(companies_with_pages)} –∫–æ–º–ø–∞–Ω–∏–π —Å {total_requests} —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏")
        print(f"üîÑ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ: {REQUESTS_PER_SECOND} –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ")
    
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–ø–∏—Å–∫–∞ –∫–æ–º–ø–∞–Ω–∏–π (–¥–æ 500-–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã)
        list_pages = list(range(1, 501))  # –°—Ç—Ä–∞–Ω–∏—Ü—ã 1-500
        list_tasks = [(page, "list") for page in list_pages]
        
        total_list_requests = len(list_tasks)
        total_company_requests = len(tasks)
        total_all_requests = total_company_requests + total_list_requests
        
        print(f"\nüìã –ò—Ç–æ–≥–æ –∑–∞–¥–∞—á:")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–º–ø–∞–Ω–∏–π: {total_company_requests}")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü—ã —Å–ø–∏—Å–∫–∞: {total_list_requests}")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_all_requests}")
        
        if total_all_requests == 0:
            print("‚ùå –ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
        semaphore = asyncio.Semaphore(REQUESTS_PER_SECOND)
        
        total_start = time.time()
        
        # –°–æ–∑–¥–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ {total_all_requests} –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ...\n")
        
        async def process_company_task(company_id: int, page: int, company_name: str, task_num: int):
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–º–ø–∞–Ω–∏–∏"""
            result = await load_page_with_stats(
                client, company_id, page, semaphore, task_num, total_all_requests
            )
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            status = "‚úÖ" if result["success"] else "‚ùå"
            size_info = f"{result['html_length']:,} –±–∞–π—Ç" if result["success"] else ""
            error_info = result.get('error', result.get('status', '')) if not result["success"] else ""
            info = size_info if result["success"] else error_info
            
            # –°–æ–∫—Ä–∞—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞
            name_short = company_name[:20] + "..." if len(company_name) > 20 else company_name
            
            print(f"{status} [C{task_num:4d}/{total_all_requests}] {name_short} P:{page} {info} ({result['elapsed']:.2f}—Å)")
            
            return result
        
        async def process_list_task(page: int, task_num: int):
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–ø–∏—Å–∫–∞"""
            result = await load_list_page_with_stats(
                client, page, semaphore, task_num, total_all_requests
            )
            
            # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            status = "‚úÖ" if result["success"] else "‚ùå"
            size_info = f"{result['html_length']:,} –±–∞–π—Ç" if result["success"] else ""
            error_info = result.get('error', result.get('status', '')) if not result["success"] else ""
            info = size_info if result["success"] else error_info
            
            print(f"{status} [L{task_num:4d}/{total_all_requests}] –°–ø–∏—Å–æ–∫ P:{page} {info} ({result['elapsed']:.2f}—Å)")
            
            return result
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä—É—Ç–∏–Ω—ã –¥–ª—è –≤—Å–µ—Ö –∑–∞–¥–∞—á
        coroutines = []
        task_counter = 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü –∫–æ–º–ø–∞–Ω–∏–π
        for company_id, page, company_name in tasks:
            coroutines.append(process_company_task(company_id, page, company_name, task_counter))
            task_counter += 1
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —Å–ø–∏—Å–∫–∞
        for page, _ in list_tasks:
            coroutines.append(process_list_task(page, task_counter))
            task_counter += 1
        
        results = await asyncio.gather(*coroutines)
        
        total_elapsed = time.time() - total_start
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        successful = sum(1 for r in results if r["success"])
        failed = len(results) - successful
        avg_time = sum(r["elapsed"] for r in results) / len(results) if results else 0
        min_time = min(r["elapsed"] for r in results) if results else 0
        max_time = max(r["elapsed"] for r in results) if results else 0
        actual_rate = len(results) / total_elapsed if total_elapsed > 0 else 0
        
        print("\n" + "="*60)
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*60)
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(results)}")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {successful}")
        print(f"   –û—à–∏–±–æ–∫: {failed}")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_elapsed:.2f}—Å")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—Ä–æ—Å: {avg_time:.2f}—Å")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min_time:.2f}—Å")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_time:.2f}—Å")
        print(f"   –§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å: {actual_rate:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
        print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {REQUESTS_PER_SECOND}")
        if total_requests > 0 and total_elapsed > 0:
            theoretical_time = total_requests / REQUESTS_PER_SECOND
            speedup = theoretical_time / total_elapsed if total_elapsed > 0 else 0
            print(f"   –£—Å–∫–æ—Ä–µ–Ω–∏–µ (vs –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ): {speedup:.2f}x")
        print("="*60)
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    asyncio.run(main())

